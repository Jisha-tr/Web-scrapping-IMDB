{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import re\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.imdb.com/search/title/?title_type=feature&release_date=2020-01-01,2021-12-31&num_votes=20000,&count=20\"\n",
    "def getSoup(url):\n",
    "    \"\"\"\n",
    "    Utility function which takes a url and returns a Soup object.\n",
    "    \"\"\"\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    return soup\n",
    "def getReviews(soup):\n",
    "    '''Function returns a negative and positive review for each movie.'''\n",
    "    \n",
    "    # get a list of user ratings\n",
    "    user_review_ratings = [tag.previous_element for tag in \n",
    "                           soup.find_all('span', attrs={'class': 'point-scale'})]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # get the review tags\n",
    "    user_review_list = soup.find_all('a', attrs={'class':'title'})\n",
    "    ans = []\n",
    "    for i in range(5):\n",
    "        ans.append(user_review_list[random.randint(0, len(user_review_list) -1)])\n",
    "    links = [\"https://www.imdb.com\" + tag['href'] for tag in ans]\n",
    "    return links\n",
    "\n",
    "def getReviewText(review_url):\n",
    "    '''Returns the user review text given the review url.'''\n",
    "    \n",
    "    # get the review_url's soup\n",
    "    soup = getSoup(review_url)\n",
    "    \n",
    "    # find div tags with class text show-more__control\n",
    "    tag = soup.find('div', attrs={'class': 'text show-more__control'})\n",
    "    \n",
    "    return tag.getText()\n",
    "\n",
    "def getMovieTitle(review_url):\n",
    "    '''Returns the movie title from the review url.'''\n",
    "    \n",
    "    # get the review_url's soup\n",
    "    soup = getSoup(review_url)\n",
    "    \n",
    "    # find h1 tag\n",
    "    tag = soup.find('h1')\n",
    "    \n",
    "    return list(tag.children)[1].getText()\n",
    "\n",
    "def getNounChunks(user_review):\n",
    "    \n",
    "    # create the doc object\n",
    "    doc = nlp(user_review)\n",
    "    \n",
    "    # get a list of noun_chunks\n",
    "    noun_chunks = list(doc.noun_chunks)\n",
    "    \n",
    "    # convert noun_chunks from span objects to strings, otherwise it won't pickle\n",
    "    noun_chunks_strlist = [chunk.text for chunk in noun_chunks]\n",
    "    \n",
    "    return noun_chunks_strlist\n",
    "movies_soup = getSoup(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are a total of 20 movie titles\n",
      "Displaying 10 titles\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/title/tt2382320/',\n",
       " '/title/tt9421570/',\n",
       " '/title/tt8110232/',\n",
       " '/title/tt7097896/',\n",
       " '/title/tt1160419/',\n",
       " '/title/tt6264654/',\n",
       " '/title/tt3480822/',\n",
       " '/title/tt9376612/',\n",
       " '/title/tt3811906/',\n",
       " '/title/tt10954652/']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_tags = movies_soup.find_all('a', attrs={'class': None})\n",
    "\n",
    "# filter the a-tags to get just the titles\n",
    "movie_tags = [tag.attrs['href'] for tag in movie_tags \n",
    "              if tag.attrs['href'].startswith('/title') & tag.attrs['href'].endswith('/')]\n",
    "\n",
    "# remove duplicate links\n",
    "movie_tags = list(dict.fromkeys(movie_tags))\n",
    "\n",
    "print(\"There are a total of \" + str(len(movie_tags)) + \" movie titles\")\n",
    "print(\"Displaying 10 titles\")\n",
    "movie_tags[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are a total of 20 movie user reviews\n",
      "Displaying 10 user reviews links\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['https://www.imdb.com/title/tt2382320/reviews',\n",
       " 'https://www.imdb.com/title/tt9421570/reviews',\n",
       " 'https://www.imdb.com/title/tt8110232/reviews',\n",
       " 'https://www.imdb.com/title/tt7097896/reviews',\n",
       " 'https://www.imdb.com/title/tt1160419/reviews',\n",
       " 'https://www.imdb.com/title/tt6264654/reviews',\n",
       " 'https://www.imdb.com/title/tt3480822/reviews',\n",
       " 'https://www.imdb.com/title/tt9376612/reviews',\n",
       " 'https://www.imdb.com/title/tt3811906/reviews',\n",
       " 'https://www.imdb.com/title/tt10954652/reviews']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_url = \"https://www.imdb.com\"\n",
    "movie_links = [base_url + tag + 'reviews' for tag in movie_tags]\n",
    "print(\"There are a total of \" + str(len(movie_links)) + \" movie user reviews\")\n",
    "print(\"Displaying 10 user reviews links\")\n",
    "movie_links[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_soups = [getSoup(link) for link in movie_links]\n",
    "\n",
    "# get all 500 movie review links\n",
    "movie_review_list = [getReviews(movie_soup) for movie_soup in movie_soups]\n",
    "\n",
    "#movie_review_list = list(itertools.chain(*movie_review_list))\n",
    "#print(len(movie_review_list))\n",
    "\n",
    "#print(\"There are a total of \" + str(len(movie_review_list)) + \" individual movie reviews\")\n",
    "#print(\"Displaying 10 reviews\")\n",
    "#movie_review_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "There are a total of 100 individual movie reviews\n",
      "Displaying 10 reviews\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['https://www.imdb.com/review/rw7412789/',\n",
       " 'https://www.imdb.com/review/rw7442432/',\n",
       " 'https://www.imdb.com/review/rw7412789/',\n",
       " 'https://www.imdb.com/review/rw7412789/',\n",
       " 'https://www.imdb.com/review/rw7423129/',\n",
       " 'https://www.imdb.com/review/rw7441337/',\n",
       " 'https://www.imdb.com/review/rw7412168/',\n",
       " 'https://www.imdb.com/review/rw7420451/',\n",
       " 'https://www.imdb.com/review/rw7403529/',\n",
       " 'https://www.imdb.com/review/rw7350535/']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "movie_review_list = list(itertools.chain(*movie_review_list))\n",
    "print(len(movie_review_list))\n",
    "\n",
    "print(\"There are a total of \" + str(len(movie_review_list)) + \" individual movie reviews\")\n",
    "print(\"Displaying 10 reviews\")\n",
    "movie_review_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_texts = [getReviewText(url) for url in movie_review_list]\n",
    "\n",
    "# get movie name from the review link\n",
    "movie_titles = [getMovieTitle(url) for url in movie_review_list]\n",
    "\n",
    "# label each review with negative or positive\n",
    "\n",
    "# construct a dataframe\n",
    "df = pd.DataFrame({'movie': movie_titles, 'user_review_permalink': movie_review_list,\n",
    "             'user_review': review_texts })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie</th>\n",
       "      <th>user_review_permalink</th>\n",
       "      <th>user_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No Time to Die</td>\n",
       "      <td>https://www.imdb.com/review/rw7412789/</td>\n",
       "      <td>\"NO TIME TO DIE, with a record-breaking 163-mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No Time to Die</td>\n",
       "      <td>https://www.imdb.com/review/rw7442432/</td>\n",
       "      <td>STAR RATING: ***** Saturday Night **** Friday ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No Time to Die</td>\n",
       "      <td>https://www.imdb.com/review/rw7412789/</td>\n",
       "      <td>\"NO TIME TO DIE, with a record-breaking 163-mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>No Time to Die</td>\n",
       "      <td>https://www.imdb.com/review/rw7412789/</td>\n",
       "      <td>\"NO TIME TO DIE, with a record-breaking 163-mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>No Time to Die</td>\n",
       "      <td>https://www.imdb.com/review/rw7423129/</td>\n",
       "      <td>NO TIME TO DIE (2021) ***1/2 Daniel Craig, Lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The Guilty</td>\n",
       "      <td>https://www.imdb.com/review/rw7441337/</td>\n",
       "      <td>30 minutes in and you realize that you do not ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The Guilty</td>\n",
       "      <td>https://www.imdb.com/review/rw7412168/</td>\n",
       "      <td>The bad: nothing in particular, BUT the execut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Guilty</td>\n",
       "      <td>https://www.imdb.com/review/rw7420451/</td>\n",
       "      <td>Before you spend (waste) anymore time here rea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The Guilty</td>\n",
       "      <td>https://www.imdb.com/review/rw7403529/</td>\n",
       "      <td>\"The Guilty\" is yet another very unusual film ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The Guilty</td>\n",
       "      <td>https://www.imdb.com/review/rw7350535/</td>\n",
       "      <td>Director Antoine Fuqua also did his best with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>The Many Saints of Newark</td>\n",
       "      <td>https://www.imdb.com/review/rw7408398/</td>\n",
       "      <td>I saw \"The Many Saints of Newark\", starring Al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>The Many Saints of Newark</td>\n",
       "      <td>https://www.imdb.com/review/rw7401612/</td>\n",
       "      <td>\"The Many Saints of Newark\" (2021 release; 120...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>The Many Saints of Newark</td>\n",
       "      <td>https://www.imdb.com/review/rw7425169/</td>\n",
       "      <td>I loved the Sopranos . I watched it religiousl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>The Many Saints of Newark</td>\n",
       "      <td>https://www.imdb.com/review/rw7414633/</td>\n",
       "      <td>. . . THE MANY SAINTS OF NEWARK by saying with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>The Many Saints of Newark</td>\n",
       "      <td>https://www.imdb.com/review/rw7411343/</td>\n",
       "      <td>Add a star if you are from Newark and grew up ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Venom: Let There Be Carnage</td>\n",
       "      <td>https://www.imdb.com/review/rw7396344/</td>\n",
       "      <td>I had a good time with this movie. It's fun an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Venom: Let There Be Carnage</td>\n",
       "      <td>https://www.imdb.com/review/rw7398834/</td>\n",
       "      <td>I saw \"Venom:Let There Be Carnage\", starring T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Venom: Let There Be Carnage</td>\n",
       "      <td>https://www.imdb.com/review/rw7395722/</td>\n",
       "      <td>I absolutely loved this sequel, I wish that it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Venom: Let There Be Carnage</td>\n",
       "      <td>https://www.imdb.com/review/rw7418303/</td>\n",
       "      <td>Sequels can be scary. First, they must live up...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Venom: Let There Be Carnage</td>\n",
       "      <td>https://www.imdb.com/review/rw7443866/</td>\n",
       "      <td>Venom: Let There Be Carnage continues with the...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          movie                   user_review_permalink  \\\n",
       "0                No Time to Die  https://www.imdb.com/review/rw7412789/   \n",
       "1                No Time to Die  https://www.imdb.com/review/rw7442432/   \n",
       "2                No Time to Die  https://www.imdb.com/review/rw7412789/   \n",
       "3                No Time to Die  https://www.imdb.com/review/rw7412789/   \n",
       "4                No Time to Die  https://www.imdb.com/review/rw7423129/   \n",
       "5                    The Guilty  https://www.imdb.com/review/rw7441337/   \n",
       "6                    The Guilty  https://www.imdb.com/review/rw7412168/   \n",
       "7                    The Guilty  https://www.imdb.com/review/rw7420451/   \n",
       "8                    The Guilty  https://www.imdb.com/review/rw7403529/   \n",
       "9                    The Guilty  https://www.imdb.com/review/rw7350535/   \n",
       "10    The Many Saints of Newark  https://www.imdb.com/review/rw7408398/   \n",
       "11    The Many Saints of Newark  https://www.imdb.com/review/rw7401612/   \n",
       "12    The Many Saints of Newark  https://www.imdb.com/review/rw7425169/   \n",
       "13    The Many Saints of Newark  https://www.imdb.com/review/rw7414633/   \n",
       "14    The Many Saints of Newark  https://www.imdb.com/review/rw7411343/   \n",
       "15  Venom: Let There Be Carnage  https://www.imdb.com/review/rw7396344/   \n",
       "16  Venom: Let There Be Carnage  https://www.imdb.com/review/rw7398834/   \n",
       "17  Venom: Let There Be Carnage  https://www.imdb.com/review/rw7395722/   \n",
       "18  Venom: Let There Be Carnage  https://www.imdb.com/review/rw7418303/   \n",
       "19  Venom: Let There Be Carnage  https://www.imdb.com/review/rw7443866/   \n",
       "\n",
       "                                          user_review  \n",
       "0   \"NO TIME TO DIE, with a record-breaking 163-mi...  \n",
       "1   STAR RATING: ***** Saturday Night **** Friday ...  \n",
       "2   \"NO TIME TO DIE, with a record-breaking 163-mi...  \n",
       "3   \"NO TIME TO DIE, with a record-breaking 163-mi...  \n",
       "4   NO TIME TO DIE (2021) ***1/2 Daniel Craig, Lea...  \n",
       "5   30 minutes in and you realize that you do not ...  \n",
       "6   The bad: nothing in particular, BUT the execut...  \n",
       "7   Before you spend (waste) anymore time here rea...  \n",
       "8   \"The Guilty\" is yet another very unusual film ...  \n",
       "9   Director Antoine Fuqua also did his best with ...  \n",
       "10  I saw \"The Many Saints of Newark\", starring Al...  \n",
       "11  \"The Many Saints of Newark\" (2021 release; 120...  \n",
       "12  I loved the Sopranos . I watched it religiousl...  \n",
       "13  . . . THE MANY SAINTS OF NEWARK by saying with...  \n",
       "14  Add a star if you are from Newark and grew up ...  \n",
       "15  I had a good time with this movie. It's fun an...  \n",
       "16  I saw \"Venom:Let There Be Carnage\", starring T...  \n",
       "17  I absolutely loved this sequel, I wish that it...  \n",
       "18  Sequels can be scary. First, they must live up...  \n",
       "19  Venom: Let There Be Carnage continues with the...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "23784c1f7cb08f751fc8275aaeeb793366452f178ab646d6f5c554e80b94c083"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
